{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1.jpg', 'p.jpg', 'elon.jpeg', 'meenutest.jpg', '4.jpg', 'elonhat.jpeg', '2.jpg', 'meenu.jpg', 'bill.jpeg']\n",
      "['1', 'p', 'elon', 'meenutest', '4', 'elonhat', '2', 'meenu', 'bill']\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "path='images'\n",
    "images=[]\n",
    "classnames=[]\n",
    "mylist=os.listdir(path)\n",
    "print(mylist)\n",
    "\n",
    "for cl in mylist:\n",
    "    curimg=cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curimg)\n",
    "    classnames.append(os.path.splitext(cl)[0])\n",
    "    \n",
    "print(classnames)  \n",
    "#print(images)  \n",
    "\n",
    "def encode(images):\n",
    "    encli=[]\n",
    "    for img in images:\n",
    "        img=cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "        encodings = face_recognition.face_encodings(img)\n",
    "        if len(encodings) > 0:\n",
    "            enc=encodings[0]\n",
    "            encli.append(enc)\n",
    "    return encli\n",
    "encknown=encode(images)    \n",
    "print(len(encknown))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(348, 491, 669, 170)]\n",
      "[0.63326665 0.67639877 0.77236213 0.5914443  0.60658372 0.66991868\n",
      " 0.6130172  0.66799126 0.72879083]\n",
      "3\n",
      "ALTHAF matched\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import face_recognition\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "video_file = '' \n",
    "\n",
    "cap=cv2.VideoCapture(video_file) \n",
    "\n",
    "success,imgS=cap.read()\n",
    "\n",
    "# imgS = cv2.resize(img, (0, 0), None, 0.25, 0.5)\n",
    "# imgS=cv2.cvtColor(imgS,cv2.COLOR_BGR2RGB)\n",
    "# print(imgS)\n",
    "\n",
    "facescurframe=face_recognition.face_locations(imgS)\n",
    "print(facescurframe)\n",
    "enccurframe=face_recognition.face_encodings(imgS,facescurframe)\n",
    "#print(len(encknown))\n",
    "if facescurframe is None:\n",
    "    print('no face points')\n",
    "\n",
    "for enco,face in zip(enccurframe,facescurframe):\n",
    "    #print(len(encknown))\n",
    "    if len(encknown) > 0: \n",
    "        matches=face_recognition.compare_faces(encknown,enco)\n",
    "        facedis=face_recognition.face_distance(encknown,enco)\n",
    "        print(facedis)\n",
    "        matchindex=np.argmin(facedis)\n",
    "        print(matchindex)\n",
    "\n",
    "        if matches[matchindex]:\n",
    "            name=classnames[matchindex].upper()\n",
    "            print(name,'matched')\n",
    "            cv2.putText(imgS,f'{name} matched',(20,170),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,0,255),2)\n",
    "\n",
    "        else:\n",
    "            print('not matched')\n",
    "            cv2.putText(imgS,f'Not matched',(20,170),cv2.FONT_HERSHEY_COMPLEX,0.7,(0,0,255),2)\n",
    "\n",
    "            \n",
    "    else:\n",
    "        print('encknown is empty')\n",
    "                \n",
    "    # display the frame\n",
    "    \n",
    "    \n",
    "imgS=cv2.resize(imgS,(640,480))\n",
    "cv2.imshow('Frame', imgS)\n",
    "cv2.waitKey(10000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
